# ğŸ“Š Projeto de ExploraÃ§Ã£o â€“ Estrutura de Dados (ETL)

### Entendimento do Problema

**Contexto**:
A Super Store precisa organizar e estruturar seus dados para facilitar consultas, anÃ¡lises e decisÃµes estratÃ©gicas.

**Objetivo**:
Construir um sistema tabular relacional utilizando o modelo dimensional (star schema), com tabelas fato e dimensÃ£o, alimentado por um processo **ETL (Extract, Transform, Load)**.

## ğŸŸ¦ 2.1 Processar e preparar base de dados

### ğŸ”µ  ConexÃ£o e ImportaÃ§Ã£o dos Dados

- **Projeto ID:** `estrutura-de-dados-473122`  
- **Dataset Principal:** `dataBase`  
- **Tabela Bruta:** `superstore`

Os dados foram carregados para o BigQuery, servindo como base inicial para as etapas de limpeza, padronizaÃ§Ã£o e modelagem dimensional.

### ğŸ”µ Identificar e tratar valores nulos

Foi aplicada a query `SUM(CASE WHEN coluna IS NULL THEN 1 ELSE 0 END)` em todas as colunas da base `superstore`.  

**Resultado**: Nenhuma coluna apresentou valores nulos entre as 51.290 linhas avaliadas.

âœ… Isso indica que a base inicial jÃ¡ possuÃ­a consistÃªncia em termos de preenchimento de campos obrigatÃ³rios.

### ğŸ”µ  Identificar e tratar valores duplicados

A anÃ¡lise de duplicidade foi realizada em diferentes nÃ­veis:

- `order_id + product_id` â†’ encontrados 38 duplicados.
- ` customer_ID + region + product_name` â†’ total caiu para 33.
- VerificaÃ§Ã£o final: Chave composta (`customer_ID + order_id + product_id + order_date + ship_date`) â†’ 35 duplicados confirmados.

ğŸ“Š **Resumo da AnÃ¡lise de Duplicados**

| MÃ©trica         | Valor   |
|-----------------|---------|
| Total de linhas | 51.290  |
| Linhas Ãºnicas   | 51.255  |
| Duplicados      | 35      |

ğŸ“Œ **InterpretaÃ§Ã£o**: Os 35 registros eram totalmente redundantes, sem novas informaÃ§Ãµes. Se nÃ£o tratados, poderiam distorcer mÃ©tricas como vendas, lucro e quantidade.

âœ… **AÃ§Ã£o Tomada**: Foi criada a tabela intermediÃ¡ria `superstore_cleaned` com as duplicatas removidas, garantindo a integridade das futuras tabelas fato e dimensÃ£o.

### ğŸ”µ Identificar e tratar dados discrepantes 

Foi realizada uma anÃ¡lise de consistÃªncia em variÃ¡veis numÃ©ricas e categÃ³ricas:

- **PadronizaÃ§Ã£o aplicada**: uso de **LOWER()** e **TRIM()** para variÃ¡veis textuais, garantindo uniformidade.
  
- **FactSales**: 
- 51.255 registros vÃ¡lidos.

- Nenhum nulo nas mÃ©tricas principais.

- 12.541 registros (24,5%) com profit < 0.

Esses valores negativos foram investigados em funÃ§Ã£o dos descontos aplicados.

### ğŸ”· AnÃ¡lise de Lucro Negativo

Os registros de lucro negativo foram segmentados por faixa de desconto:

| Faixa de Desconto | Total de Registros | Registros com Lucro Negativo | % Lucro Negativo |
|-------------------|--------------------|------------------------------|------------------|
| Sem desconto      | 29.446             | 13                           | 0,04%            |
| 1% a 10%          | 4.213              | 888                          | 21,08%           |
| 11% a 20%         | 6.312              | 1.487                        | 23,56%           |
| 21% a 30%         | 924                | 575                          | 62,23%           |
| > 30%             | 10.360             | 9.578                        | 92,45%           |

ğŸ“Œ**InterpretaÃ§Ã£o**

- Pedidos sem desconto quase sempre geram lucro.

- Ã€ medida que o desconto aumenta, cresce a incidÃªncia de prejuÃ­zo.

- Acima de 30% de desconto, a maioria esmagadora dos pedidos gera lucro negativo (92,45%).

âœ… **RecomendaÃ§Ã£o**: revisar a polÃ­tica de descontos, investigando se os valores decorrem de promoÃ§Ãµes planejadas ou falhas nos processos de precificaÃ§Ã£o.

### ğŸ”· Tabela IntermediÃ¡ria Criada

Foi criada a tabela consolidada `superstore_cleaned`, com **51.255 registros vÃ¡lidos**, livre de duplicados e com variÃ¡veis padronizadas.

**VariÃ¡veis disponÃ­veis:**  
`customer_ID, customer_name, segment, product_id, product_name, category, sub_category, order_id, row_id, order_date, ship_date, sales, profit, quantity, discount, shipping_cost, order_priority, ship_mode, region, city, state, country, market, market2, year, weeknum, unknown, rn`

### ğŸ”µ Pesquisar dados de outras fontes

Para enriquecer a anÃ¡lise, foram integrados dados de concorrentes internacionais.

ğŸ“Œ **Coleta dos Dados**
A extraÃ§Ã£o foi realizada por meio de **web scraping** com a funÃ§Ã£o `IMPORTHTML` do Google Planilhas, aplicada Ã  pÃ¡gina da Wikipedia:

```
=IMPORTHTML("https://en.wikipedia.org/wiki/List_of_supermarket_chains","table",1)
```

A tabela original apresentava as seguintes colunas: Company, Headquarters, Served countries, Map, Number of locations e Number of employees.

ğŸ“Œ**Tratamento**

**Mantidas**: Company, Headquarters, Served countries (colunas consistentes).
**Descartadas**: Map, Number of locations, Number of employees (alto volume de nulos e baixa relevÃ¢ncia).
**Tratamento extra**: registros sem valores em Company ou Headquarters foram removidos.

**Resultado Final**
Tabela com informaÃ§Ãµes limpas de empresas, suas sedes e paÃ­ses de atuaÃ§Ã£o. Esse conjunto poderÃ¡ ser usado como benchmarking internacional para comparar a presenÃ§a da Super Store frente a grandes redes globais.

ğŸ“š Fonte dos Dados
ğŸ‘‰ [Wikipedia â€“ List of supermarket chains](https://en.wikipedia.org/wiki/List_of_supermarket_chains)

### ğŸ”µ Projetar estrutura de base de dados (tabelas de fatos e dimensÃµes)

Foi adotado o modelo dimensional (star schema):

Tabelas de DimensÃ£o: armazenam atributos descritivos (quem, o quÃª, onde, quando).

Tabela Fato (FactSales): centraliza eventos transacionais com mÃ©tricas (vendas, lucro, quantidade).

ğŸ“Œ **Boas prÃ¡ticas aplicadas**:

Uso de LOWER() e TRIM() â†’ padronizaÃ§Ã£o textual.

DeduplicaÃ§Ã£o de dimensÃµes.

Chaves substitutas (FARM_FINGERPRINT) â†’ garantem unicidade, mantendo IDs naturais para rastreabilidade.

ğŸ“Œ **RepresentaÃ§Ã£o Visual**:
O diagrama foi elaborado no Lucidchart, com a FactSales no centro, conectada Ã s dimensÃµes DimCustomer, DimProduct, DimDate, DimRegion, DimShipMode e DimMarket.

ğŸ‘‰ [Visualizar o diagrama](https://github.com/tha-lira/projeto-SuperStore-Rota-1/blob/main/Modelo%20Dimensional%20-%20An%C3%A1lise%20de%20Vendas%20(Star%20Schema).pdf)

### ğŸ”µ Criar estrutura de base de dados (tabelas de fatos e dimensÃµes)

**FactSales**: nÃºcleo central do modelo, com mÃ©tricas de vendas.

**DimCustomer, DimProduct, DimDate, DimRegion, DimShipMode, DimMarket**: tabelas descritivas de suporte.

ğŸ“Œ **ObservaÃ§Ãµes TÃ©cnicas**:

Modelo em estrela â†’ consultas OLAP mais simples e rÃ¡pidas.

Chaves primÃ¡rias das dimensÃµes usadas como FK na fato.

Surrogate keys via FARM_FINGERPRINT â†’ unicidade e joins eficientes.

FactSales contÃ©m apenas dados normalizados e referenciados.

ğŸ‘‰ [Estrutura detalhada do modelo dimensional](https://github.com/tha-lira/projeto-SuperStore-Rota-1/blob/main/Estrutura_Modelo_Dimesional.md)
  
### ğŸ”µ  Agendar atualizaÃ§Ãµes de tabelas

Foi projetado um pipeline lÃ³gico de atualizaÃ§Ã£o, considerando dependÃªncias:

1. Superstore (bruta): dados de entrada.

2. superstore_cleaned (intermediÃ¡ria): remoÃ§Ã£o de duplicatas e padronizaÃ§Ã£o.

3. DimensÃµes: atualizadas em seguida (DimCustomer, DimProduct, DimDate, DimRegion, DimShipMode, DimMarket).

4. FactSales: Ãºltima a ser atualizada, consolidando mÃ©tricas e conectando dimensÃµes.

âš ï¸ Neste projeto, o pipeline foi projetado apenas conceitualmente, sem automaÃ§Ã£o.

### ğŸ”µ ConclusÃ£o Final e PrÃ³ximos Passos

ğŸ“Œ **Principais Entregas**

**Qualidade dos Dados**:

- Nenhum nulo.

- 35 duplicados removidos.

- AnÃ¡lise de lucros negativos relacionada a descontos.

**Tabela IntermediÃ¡ria**:

- superstore_cleaned como base confiÃ¡vel para modelagem.

**Dados Externos**:

- Benchmarking internacional com supermercados multinacionais.

**Modelagem Dimensional**:

- Estrutura em estrela no BigQuery.

- Diagrama criado no Lucidchart.

**Pipeline (conceitual)**:

- SequÃªncia lÃ³gica definida para atualizaÃ§Ã£o das tabelas.

ğŸ“Š **BenefÃ­cios da SoluÃ§Ã£o**

- Garantia de integridade e consistÃªncia dos dados.

- Estrutura escalÃ¡vel e otimizada para consultas analÃ­ticas.

- Possibilidade de anÃ¡lises sob mÃºltiplas perspectivas (clientes, produtos, regiÃµes, perÃ­odos, modos de envio).

- Base integrada para benchmarking internacional.

ğŸš€** PrÃ³ximos Passos**

1. Automatizar o pipeline de atualizaÃ§Ã£o (Airflow, Dataflow ou Cloud Composer).

2. Aplicar Slowly Changing Dimensions (SCD) para rastrear mudanÃ§as histÃ³ricas em dimensÃµes (ex.: mudanÃ§a de regiÃ£o ou segmento de cliente).

3. Construir dashboards no Power BI ou Looker Studio para apoiar decisÃµes gerenciais.

4. Implantar monitoramento de qualidade dos dados (checagem periÃ³dica de nulos, duplicados e discrepÃ¢ncias).
